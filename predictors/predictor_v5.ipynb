{
  "cells": [
    {
      "cell_type": "markdown",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# NBA Match Predictor V5 (HistGradientBoosting)\n",
        "\n",
        "This notebook implements the final 'Matchup Merge' model with 61% accuracy.\n",
        "\n",
        "### Improvements over V2 (Ridge):\n",
        "1. **Matchup Merge**: Joins Team OFF vs Opponent OFF/DEF stats.\n",
        "2. **HistGradientBoosting**: Non-linear model handles complex interactions.\n",
        "3. **Dynamic Selection**: Picks top 50 features automatically."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.ensemble import HistGradientBoostingClassifier, GradientBoostingClassifier\n",
        "from sklearn.feature_selection import SelectFromModel\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.model_selection import train_test_split\n",
        "import joblib\n",
        "import os\n",
        "\n",
        "DATA_PATH = \"../data/nba_games_raw.csv\"\n",
        "MODEL_DIR = \"../models/hist_gbm_v5\"\n",
        "if not os.path.exists(MODEL_DIR): os.makedirs(MODEL_DIR)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 1. Load & Clean Data\n",
        "df = pd.read_csv(DATA_PATH)\n",
        "df = df.sort_values(\"date\")\n",
        "\n",
        "# Drop internal/useless columns\n",
        "if \"mp\" in df.columns: del df[\"mp\"]\n",
        "if \"mp.1\" in df.columns: del df[\"mp.1\"]\n",
        "if \"item\" in df.columns: del df[\"item\"]\n",
        "\n",
        "# Drop columns with nulls (Essential!)\n",
        "nulls = pd.isnull(df).sum()\n",
        "nulls = nulls[nulls > 0]\n",
        "valid_cols = df.columns[~df.columns.isin(nulls.index)]\n",
        "df = df[valid_cols].copy()\n",
        "\n",
        "print(f\"Cleaned Data: {df.shape}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 2. Add Targets & Next Game Info\n",
        "def add_target(team_df):\n",
        "    team_df[\"target\"] = team_df[\"won\"].shift(-1)\n",
        "    team_df[\"home_next\"] = team_df[\"home\"].shift(-1)\n",
        "    team_df[\"team_opp_next\"] = team_df[\"team_opp\"].shift(-1)\n",
        "    team_df[\"date_next\"] = team_df[\"date\"].shift(-1)\n",
        "    return team_df\n",
        "\n",
        "df = df.groupby(\"team\", group_keys=False).apply(add_target)\n",
        "\n",
        "# Drop rows where next game info is NaN\n",
        "df = df.dropna(subset=[\"target\", \"home_next\", \"team_opp_next\", \"date_next\"])\n",
        "df[\"target\"] = df[\"target\"].astype(int)\n",
        "print(f\"Data with Targets: {df.shape}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 3. Compute Rolling Averages (Last 10 Games)\n",
        "numeric_cols = df.select_dtypes(include=[np.number]).columns.tolist()\n",
        "for c in [\"season\", \"target\", \"won\", \"team\", \"team_opp\", \"date\", \"home_next\", \"team_opp_next\", \"date_next\"]:\n",
        "    if c in numeric_cols: numeric_cols.remove(c)\n",
        "\n",
        "def find_team_averages(team):\n",
        "    rolling = team[numeric_cols].rolling(10).mean()\n",
        "    return rolling\n",
        "\n",
        "df_rolling = df.groupby([\"team\"], group_keys=False).apply(find_team_averages)\n",
        "roll_cols = [f\"{c}_10\" for c in df_rolling.columns]\n",
        "df_rolling.columns = roll_cols\n",
        "\n",
        "# Concatenate\n",
        "df = pd.concat([df, df_rolling], axis=1)\n",
        "df = df.dropna()\n",
        "print(f\"Data with Rolling Stats: {df.shape}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 4. The Matchup Merge (Team vs Opponent)\n",
        "# We match Team A (Left) with Team B (Right) on Date + Opponent ID\n",
        "stats_cols = roll_cols + [\"team\", \"date_next\"]\n",
        "right_df = df[stats_cols].copy()\n",
        "\n",
        "combined = pd.merge(\n",
        "    df, right_df, \n",
        "    left_on=[\"team_opp_next\", \"date_next\"], \n",
        "    right_on=[\"team\", \"date_next\"],\n",
        "    suffixes=(\"_team\", \"_opp\")\n",
        ")\n",
        "combined = combined.dropna()\n",
        "print(f\"Final Merged Data Shape: {combined.shape}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 5. Feature Selection (Top 50)\n",
        "predictors = [c for c in combined.columns if \"_10\" in c or c == \"home_next\"]\n",
        "\n",
        "# Split Last 15% as Test\n",
        "split_idx = int(len(combined) * 0.85)\n",
        "train_df = combined.iloc[:split_idx]\n",
        "test_df = combined.iloc[split_idx:]\n",
        "\n",
        "X_train = train_df[predictors]\n",
        "y_train = train_df[\"target\"]\n",
        "X_test = test_df[predictors]\n",
        "y_test = test_df[\"target\"]\n",
        "\n",
        "scaler = MinMaxScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "# Gradient Boosting for Feature Importance\n",
        "print(\"Selecting Best Features...\")\n",
        "sel = GradientBoostingClassifier(n_estimators=50, max_depth=3, random_state=42)\n",
        "sel.fit(X_train_scaled, y_train)\n",
        "\n",
        "importances = sel.feature_importances_\n",
        "top_k = 50\n",
        "top_indices = np.argsort(importances)[::-1][:top_k]\n",
        "selected_predictors = [predictors[i] for i in top_indices]\n",
        "\n",
        "print(f\"Selected {len(selected_predictors)} Predictors.\")\n",
        "print(selected_predictors[:10])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 6. Final Training: HistGradientBoosting\n",
        "scaler_final = MinMaxScaler()\n",
        "X_train_final = scaler_final.fit_transform(train_df[selected_predictors])\n",
        "X_test_final = scaler_final.transform(test_df[selected_predictors])\n",
        "\n",
        "model = HistGradientBoostingClassifier(max_iter=100, max_depth=5, learning_rate=0.1, random_state=42)\n",
        "model.fit(X_train_final, y_train)\n",
        "\n",
        "preds = model.predict(X_test_final)\n",
        "acc = accuracy_score(y_test, preds)\n",
        "print(f\"Validation Accuracy: {acc:.4f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 7. Save Artifacts\n",
        "joblib.dump(model, f\"{MODEL_DIR}/model_v5.pkl\")\n",
        "joblib.dump(scaler_final, f\"{MODEL_DIR}/scaler_v5.pkl\")\n",
        "joblib.dump(selected_predictors, f\"{MODEL_DIR}/predictors_v5.pkl\")\n",
        "print(\"Model saved!\")"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}